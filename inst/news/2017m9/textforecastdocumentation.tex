\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={TextForecast R package documentation},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{TextForecast R package documentation}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{true \\ true}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{2019-01-05}


\begin{document}
\maketitle

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\section{Introduction}\label{introduction}

This vignettes shows the functions and examples of the
\textbf{TextForecast} package. The package functions are based on the
Lima, Godeiro, and Mohsin (2018) paper and L. Godeiro (2018)
Ph.D.~thesis.

\section{Installation}\label{installation}

You can install the released version of TextForecast from github with:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{)}
\KeywordTok{library}\NormalTok{(devtools)}
\NormalTok{devtools}\OperatorTok{::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"lucasgodeiro/TextForecast"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{get\_words function}\label{get_words-function}

This function counts the words of the texts in the PDF format.

\subsection{Arguments}\label{arguments}

\textbf{corpus\_dates:} A vector of characters indicating the subfolders
where are located the texts.

\textbf{ntrms:} maximum numbers of words that will be filtered by
tf-idf. We rank the word by tf-idf in a decreasing order. Then, we
select the words with the ntrms highest tf-idf.

\textbf{st:} set 0 to stem the words and 1 otherwise.

\textbf{path\_name:} the folders path where the subfolders with the
dates are located.

\subsection{Value}\label{value}

a list containing a matrix with the all words counting and another with
a td-idf filtered words couting according to the ntrms.

\subsection{Example}\label{example}

This is a basic example which shows you how todo a word counting from
PDF files. The PDF files contains monthly financial News from The Wall
Street Journal and The New York Times between 2017 and 2018.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{## Example from function get_words. }
\KeywordTok{library}\NormalTok{(TextForecast)}
\NormalTok{st_year=}\DecValTok{2017}
\NormalTok{end_year=}\DecValTok{2018}
\NormalTok{path_name=}\KeywordTok{system.file}\NormalTok{(}\StringTok{"news"}\NormalTok{,}\DataTypeTok{package=}\StringTok{"TextForecast"}\NormalTok{)}
\NormalTok{qt=}\KeywordTok{paste0}\NormalTok{(}\KeywordTok{sort}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from=}\NormalTok{st_year,}\DataTypeTok{to=}\NormalTok{end_year,}\DataTypeTok{by=}\DecValTok{1}\NormalTok{),}\DecValTok{12}\NormalTok{)),}
\KeywordTok{c}\NormalTok{(}\StringTok{"m1"}\NormalTok{,}\StringTok{"m2"}\NormalTok{,}\StringTok{"m3"}\NormalTok{,}\StringTok{"m4"}\NormalTok{,}\StringTok{"m5"}\NormalTok{,}\StringTok{"m6"}\NormalTok{,}\StringTok{"m7"}\NormalTok{,}\StringTok{"m8"}\NormalTok{,}\StringTok{"m9"}\NormalTok{,}\StringTok{"m10"}\NormalTok{,}\StringTok{"m11"}\NormalTok{,}\StringTok{"m12"}\NormalTok{))}
\NormalTok{z_wrd=}\KeywordTok{get_words}\NormalTok{(}\DataTypeTok{corpus_dates=}\NormalTok{qt[}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{],}\DataTypeTok{path_name=}\NormalTok{path_name,}\DataTypeTok{ntrms=}\DecValTok{10}\NormalTok{,}\DataTypeTok{st=}\DecValTok{0}\NormalTok{)}
\NormalTok{zz=z_wrd[[}\DecValTok{2}\NormalTok{]]}
\KeywordTok{head}\NormalTok{(zz)}
\end{Highlighting}
\end{Shaded}

\section{get\_collocations function}\label{get_collocations-function}

This function counts the collocations of the texts in the PDF format.
The PDF files contains monthly financial News from The Wall Street
Journal and The New York Times between 2017 and 2018.

\subsection{Arguments}\label{arguments-1}

\textbf{corpus\_dates:} a character vector indicating the subfolders
where are located the texts.

\textbf{path\_name:} the folders path where the subfolders with the
dates are located.

\textbf{ntrms:} maximum numbers of collocations that will be filtered by
tf-idf. We rank the collocations by tf-idf in a decreasing order. Then,
after we select the words with the ntrms highest tf-idf.

\textbf{ngrams\_number:} integer indicating the size of the
collocations. Defaults to 2, indicating to compute bigrams. If set to 3,
will find collocations of bigrams and trigrams.

\textbf{min\_freq:} integer indicating the frequency of how many times a
collocation should at least occur in the data in order to be returned.

\subsection{Value}\label{value-1}

a list containing a matrix with the all collocations counting and
another with a td-idf filtered collocations couting according to the
ntrms.

\subsection{Example}\label{example-1}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(TextForecast)}
\NormalTok{st_year=}\DecValTok{2017}
\NormalTok{end_year=}\DecValTok{2018}
\NormalTok{path_name=}\KeywordTok{system.file}\NormalTok{(}\StringTok{"news"}\NormalTok{,}\DataTypeTok{package=}\StringTok{"TextForecast"}\NormalTok{)}
\NormalTok{qt=}\KeywordTok{paste0}\NormalTok{(}\KeywordTok{sort}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from=}\NormalTok{st_year,}\DataTypeTok{to=}\NormalTok{end_year,}\DataTypeTok{by=}\DecValTok{1}\NormalTok{),}\DecValTok{12}\NormalTok{)),}
\KeywordTok{c}\NormalTok{(}\StringTok{"m1"}\NormalTok{,}\StringTok{"m2"}\NormalTok{,}\StringTok{"m3"}\NormalTok{,}\StringTok{"m4"}\NormalTok{,}\StringTok{"m5"}\NormalTok{,}\StringTok{"m6"}\NormalTok{,}\StringTok{"m7"}\NormalTok{,}\StringTok{"m8"}\NormalTok{,}\StringTok{"m9"}\NormalTok{,}\StringTok{"m10"}\NormalTok{,}\StringTok{"m11"}\NormalTok{,}\StringTok{"m12"}\NormalTok{))}
\NormalTok{z_coll=}\KeywordTok{get_collocations}\NormalTok{(}\DataTypeTok{corpus_dates=}\NormalTok{qt[}\DecValTok{1}\OperatorTok{:}\DecValTok{23}\NormalTok{],}\DataTypeTok{path_name=}\NormalTok{path_name,}
\DataTypeTok{ntrms=}\DecValTok{20}\NormalTok{,}\DataTypeTok{ngrams_number=}\DecValTok{3}\NormalTok{,}\DataTypeTok{min_freq=}\DecValTok{10}\NormalTok{)}
\NormalTok{zz=z_coll[[}\DecValTok{2}\NormalTok{]]}
\CommentTok{#head(zz)}
\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}\KeywordTok{head}\NormalTok{(zz, }\DecValTok{23}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\section{get\_terms function}\label{get_terms-function}

This function counts the terms of the texts in the PDF format.

\subsection{Arguments}\label{arguments-2}

\textbf{corpus\_dates:} a character vector indicating the subfolders
where are located the texts.

\textbf{ntrms\_words:} maximum numbers of words that will be filtered by
tf-idf. We rank the word by tf-idf in a decreasing order. Then, we
select the words with the ntrms highest tf-idf.

\textbf{st:} set 0 to stem the words and 1 otherwise.

\textbf{path.name:} the folders path where the subfolders with the dates
are located.

\textbf{ntrms\_collocation:} maximum numbers of collocations that will
be filtered by tf-idf. We rank the collocations by tf-idf in a
decreasing order. Then, after we select the words with the ntrms highest
tf-idf.

\textbf{ngrams\_number:} integer indicating the size of the
collocations. Defaults to 2, indicating to compute bigrams. If set to 3,
will find collocations of bigrams and trigrams.

\textbf{min\_freq:} integer indicating the frequency of how many times a
collocation should at least occur in the data in order to be returned.

\subsection{Value}\label{value-2}

a list containing a matrix with the all collocations and words couting
and another with a td-idf filtered collocations and words counting
according to the ntrms.

\subsection{Example}\label{example-2}

This function counts the words and collocations of the texts in the PDF
format. The PDF files contains monthly financial News from The Wall
Street Journal and The New York Times between 2017 and 2018.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(TextForecast)}
\NormalTok{st_year=}\DecValTok{2017}
\NormalTok{end_year=}\DecValTok{2018}
\NormalTok{path_name=}\KeywordTok{system.file}\NormalTok{(}\StringTok{"news"}\NormalTok{,}\DataTypeTok{package=}\StringTok{"TextForecast"}\NormalTok{)}
\NormalTok{qt=}\KeywordTok{paste0}\NormalTok{(}\KeywordTok{sort}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from=}\NormalTok{st_year,}\DataTypeTok{to=}\NormalTok{end_year,}\DataTypeTok{by=}\DecValTok{1}\NormalTok{),}\DecValTok{12}\NormalTok{)),}
\KeywordTok{c}\NormalTok{(}\StringTok{"m1"}\NormalTok{,}\StringTok{"m2"}\NormalTok{,}\StringTok{"m3"}\NormalTok{,}\StringTok{"m4"}\NormalTok{,}\StringTok{"m5"}\NormalTok{,}\StringTok{"m6"}\NormalTok{,}\StringTok{"m7"}\NormalTok{,}\StringTok{"m8"}\NormalTok{,}\StringTok{"m9"}\NormalTok{,}\StringTok{"m10"}\NormalTok{,}\StringTok{"m11"}\NormalTok{,}\StringTok{"m12"}\NormalTok{))}
\NormalTok{z_terms=}\KeywordTok{get_terms}\NormalTok{(}\DataTypeTok{corpus_dates=}\NormalTok{qt[}\DecValTok{1}\OperatorTok{:}\DecValTok{23}\NormalTok{],}\DataTypeTok{path.name=}\NormalTok{path_name,}\DataTypeTok{ntrms_words=}\DecValTok{10}\NormalTok{,}
\DataTypeTok{ngrams_number=}\DecValTok{3}\NormalTok{,}\DataTypeTok{st=}\DecValTok{0}\NormalTok{,}\DataTypeTok{ntrms_collocation=}\DecValTok{10}\NormalTok{,}\DataTypeTok{min_freq=}\DecValTok{10}\NormalTok{)}
\NormalTok{zz=z_terms[[}\DecValTok{2}\NormalTok{]]}
\CommentTok{#head(zz,23)}
\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}\KeywordTok{head}\NormalTok{(zz, }\DecValTok{23}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\section{tf-idf function}\label{tf-idf-function}

This function computes the terms tf-idf.

\subsection{Arguments}\label{arguments-3}

\textbf{x:} a input matrix x of terms counting.

\subsection{Value}\label{value-3}

a list with the terms tf-idf and the terms tf-idf in descending order.

\subsection{Example}\label{example-3}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(TextForecast)}
 \KeywordTok{data}\NormalTok{(}\StringTok{"news_data"}\NormalTok{)}
\NormalTok{ X=}\KeywordTok{as.matrix}\NormalTok{(news_data[,}\DecValTok{2}\OperatorTok{:}\KeywordTok{ncol}\NormalTok{(news_data)])}
\NormalTok{  tf_idf=}\KeywordTok{tf_idf}\NormalTok{(X)}
  \KeywordTok{head}\NormalTok{(tf_idf[[}\DecValTok{1}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\section{optimal alphas function}\label{optimal-alphas-function}

This functions computes the optimal alphas.

\subsection{Arguments}\label{arguments-4}

\textbf{x:} A matrix of variables to be selected by shrinkrage methods.

\textbf{w:} Optional Argument. A matrix or vector of variables that
cannot be selected(no shrinkrage).

\textbf{y:} response variable.

\textbf{grid\_alphas:} a grid of alphas between 0 and 1.

\textbf{cont\_folds:} Set TRUE for contiguous folds used in time
depedent data.

\textbf{family} The glmnet family.

\subsection{Value}\label{value-4}

\textbf{lambdas\_opt:} a vector with the optimal alpha and lambda.

\subsection{Example}\label{example-4}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(TextForecast)}
 \KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
 \KeywordTok{data}\NormalTok{(}\StringTok{"stock_data"}\NormalTok{)}
 \KeywordTok{data}\NormalTok{(}\StringTok{"news_data"}\NormalTok{)}
\NormalTok{ y=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{2}\NormalTok{])}
\NormalTok{ w=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{3}\NormalTok{])}
 \KeywordTok{data}\NormalTok{(}\StringTok{"news_data"}\NormalTok{)}
\NormalTok{ X=news_data[,}\DecValTok{2}\OperatorTok{:}\KeywordTok{ncol}\NormalTok{(news_data)]}
\NormalTok{ x=}\KeywordTok{as.matrix}\NormalTok{(X)}
\NormalTok{ grid_alphas=}\KeywordTok{seq}\NormalTok{(}\DataTypeTok{by=}\FloatTok{0.05}\NormalTok{,}\DataTypeTok{to=}\FloatTok{0.95}\NormalTok{,}\DataTypeTok{from=}\FloatTok{0.05}\NormalTok{)}
\NormalTok{ cont_folds=}\OtherTok{TRUE}
\NormalTok{ t=}\KeywordTok{length}\NormalTok{(y)}
\NormalTok{ optimal_alphas=}\KeywordTok{optimal_alphas}\NormalTok{(x[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],}
\NormalTok{ w[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],y[}\DecValTok{2}\OperatorTok{:}\NormalTok{t],grid_alphas,}\OtherTok{TRUE}\NormalTok{,}\StringTok{"gaussian"}\NormalTok{)}
 \KeywordTok{print}\NormalTok{(optimal_alphas)}
\end{Highlighting}
\end{Shaded}

\section{tv dictionary function}\label{tv-dictionary-function}

This functions selects from \(X\) the most predictive terms \(X^{\ast}\)
using supervised machine learning techniques(Elastic Net).

\subsection{Arguments}\label{arguments-5}

\textbf{x:} A matrix of variables to be selected by shrinkrage methods.

\textbf{w:} Optional Argument. A matrix or vector of variables that
cannot be selected(no shrinkrage).

\textbf{y:} response variable.

\textbf{alpha:} the alpha required in glmnet.

\textbf{lambda:} the lambda required in glmnet.

\textbf{newx:} Matrix that selection will applied. Useful for time
series, when we need the observation at time t.

\textbf{family:} the glmnet family.

\subsection{Value}\label{value-5}

\(X_{t}^{\ast}\): a list with the coefficients and a matrix with the
most predictive terms.

\subsection{Example}\label{example-5}

This example select the most predictive words from the news database.
The news database contains the terms counting of the Wall street journal
and the New York Times financial news.

\begin{Shaded}
\begin{Highlighting}[]
 \KeywordTok{library}\NormalTok{(TextForecast)}
 \KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
 \KeywordTok{data}\NormalTok{(}\StringTok{"stock_data"}\NormalTok{)}
 \KeywordTok{data}\NormalTok{(}\StringTok{"news_data"}\NormalTok{)}
\NormalTok{ y=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{2}\NormalTok{])}
\NormalTok{ w=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{3}\NormalTok{])}
 \KeywordTok{data}\NormalTok{(}\StringTok{"news_data"}\NormalTok{)}
\NormalTok{ X=news_data[,}\DecValTok{2}\OperatorTok{:}\KeywordTok{ncol}\NormalTok{(news_data)]}
\NormalTok{ x=}\KeywordTok{as.matrix}\NormalTok{(X)}
\NormalTok{ grid_alphas=}\KeywordTok{seq}\NormalTok{(}\DataTypeTok{by=}\FloatTok{0.05}\NormalTok{,}\DataTypeTok{to=}\FloatTok{0.95}\NormalTok{,}\DataTypeTok{from=}\FloatTok{0.05}\NormalTok{)}
\NormalTok{ cont_folds=}\OtherTok{TRUE}
\NormalTok{ t=}\KeywordTok{length}\NormalTok{(y)}
\NormalTok{ optimal_alphas=}\KeywordTok{optimal_alphas}\NormalTok{(}\DataTypeTok{x=}\NormalTok{x[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],}\DataTypeTok{w=}\NormalTok{w[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],}
 \DataTypeTok{y=}\NormalTok{y[}\DecValTok{2}\OperatorTok{:}\NormalTok{t],}\DataTypeTok{grid_alphas=}\NormalTok{grid_alphas,}\DataTypeTok{cont_folds=}\OtherTok{TRUE}\NormalTok{,}\DataTypeTok{family=}\StringTok{"gaussian"}\NormalTok{)}
\NormalTok{ x_star=}\KeywordTok{tv_dictionary}\NormalTok{(}\DataTypeTok{x=}\NormalTok{x[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],}\DataTypeTok{w=}\NormalTok{w[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],}
 \DataTypeTok{y=}\NormalTok{y[}\DecValTok{2}\OperatorTok{:}\NormalTok{t],}\DataTypeTok{alpha=}\NormalTok{optimal_alphas[}\DecValTok{1}\NormalTok{],}\DataTypeTok{lambda=}\NormalTok{optimal_alphas[}\DecValTok{2}\NormalTok{],}\DataTypeTok{newx=}\NormalTok{x,}\DataTypeTok{family=}\StringTok{"gaussian"}\NormalTok{)}
\NormalTok{ optimal_alphas1=}\KeywordTok{optimal_alphas}\NormalTok{(}\DataTypeTok{x=}\NormalTok{x[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],}\DataTypeTok{y=}\NormalTok{y[}\DecValTok{2}\OperatorTok{:}\NormalTok{t],}
 \DataTypeTok{grid_alphas=}\NormalTok{grid_alphas,}\DataTypeTok{cont_folds=}\OtherTok{TRUE}\NormalTok{,}\DataTypeTok{family=}\StringTok{"gaussian"}\NormalTok{)}
\NormalTok{ x_star1=}\KeywordTok{tv_dictionary}\NormalTok{(}\DataTypeTok{x=}\NormalTok{x[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],}\DataTypeTok{y=}\NormalTok{y[}\DecValTok{2}\OperatorTok{:}\NormalTok{t],}\DataTypeTok{alpha=}\NormalTok{optimal_alphas1[}\DecValTok{1}\NormalTok{],}
 \DataTypeTok{lambda=}\NormalTok{optimal_alphas1[}\DecValTok{2}\NormalTok{],}\DataTypeTok{newx=}\NormalTok{x,}\DataTypeTok{family=}\StringTok{"gaussian"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{Optimal number of factors
function}\label{optimal-number-of-factors-function}

This function computes the optimal number of factors according to Ahn
and Horenstein (2013).

\subsection{Arguments}\label{arguments-6}

**\url{data:**} a input matrix X.

\textbf{kmax:} the maximum number of factors.

\subsection{Value}\label{value-6}

a list with the optimal factors.

\subsection{Example}\label{example-6}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(TextForecast)}
\KeywordTok{data}\NormalTok{(}\StringTok{"optimal_x"}\NormalTok{)}
\NormalTok{optimal_factor <-}\StringTok{ }\NormalTok{TextForecast}\OperatorTok{::}\KeywordTok{optimal_factors}\NormalTok{(}\DataTypeTok{data=}\NormalTok{optimal_x,}\DataTypeTok{kmax=}\DecValTok{8}\NormalTok{)}
\KeywordTok{head}\NormalTok{(optimal_factor[[}\DecValTok{1}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\section{Hard thresholding function}\label{hard-thresholding-function}

This function carries out the hard thresholding according to Bai and Ng
(2008)

\subsection{Arguments}\label{arguments-7}

\textbf{x:} the input matrix x.

\textbf{w:} Optional Argument. The optional input matrix w, that cannot
be selected.

\textbf{y:} the response variable.

\textbf{p\_value:} the threshold p-value.

\textbf{newx:} matrix that selection will applied. Useful for time
series, when we need the observation at time t.

\subsection{Value}\label{value-7}

the variables less than p-value.

\subsection{Example}\label{example-7}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(TextForecast)}
\KeywordTok{data}\NormalTok{(}\StringTok{"stock_data"}\NormalTok{)}
\KeywordTok{data}\NormalTok{(}\StringTok{"optimal_factors"}\NormalTok{)}
\NormalTok{y=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{2}\NormalTok{])}
\NormalTok{y=}\KeywordTok{as.vector}\NormalTok{(y)}
\NormalTok{w=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{3}\NormalTok{])}
\NormalTok{pc=}\KeywordTok{as.matrix}\NormalTok{(optimal_factors)}
\NormalTok{t=}\KeywordTok{length}\NormalTok{(y)}
\NormalTok{news_factor <-}\StringTok{ }\KeywordTok{hard_thresholding}\NormalTok{(}\DataTypeTok{w=}\NormalTok{w[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],}
\DataTypeTok{x=}\NormalTok{pc[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],}\DataTypeTok{y=}\NormalTok{y[}\DecValTok{2}\OperatorTok{:}\NormalTok{t],}\DataTypeTok{p_value =} \FloatTok{0.01}\NormalTok{,}\DataTypeTok{newx =}\NormalTok{ pc)}
\end{Highlighting}
\end{Shaded}

\section{Text Forecast function}\label{text-forecast-function}

This functions computes the \(h\) step ahead forecast based on textual
and/or economic data.

\subsection{Arguments}\label{arguments-8}

\textbf{x:} the input matrix x.

\textbf{y:} the response variable

\textbf{h:} the forecast horizon

\textbf{intercept:} TRUE for include intercept in the forecast equation.

\subsection{Value}\label{value-8}

The h step ahead forecast

\subsection{Example}\label{example-8}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(TextForecast)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\KeywordTok{data}\NormalTok{(}\StringTok{"stock_data"}\NormalTok{)}
\NormalTok{y=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{2}\NormalTok{])}
\NormalTok{w=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{3}\NormalTok{])}
\KeywordTok{data}\NormalTok{(}\StringTok{"optimal_factors_data"}\NormalTok{)}
\NormalTok{pc=}\KeywordTok{as.matrix}\NormalTok{(optimal_factors)}
\NormalTok{z=}\KeywordTok{cbind}\NormalTok{(w,pc)}
\NormalTok{fcsts=}\KeywordTok{text_forecast}\NormalTok{(z,y,}\DecValTok{1}\NormalTok{,}\OtherTok{TRUE}\NormalTok{)}
\KeywordTok{print}\NormalTok{(fcsts)}
\end{Highlighting}
\end{Shaded}

\section{Text Nowcast function}\label{text-nowcast-function}

This function computes the nowcast h=0.

\subsection{Arguments}\label{arguments-9}

\textbf{x:} the input matrix x.

\textbf{y:} the response variable

\textbf{intercept:} TRUE for include intercept in the forecast equation.

\subsection{Value}\label{value-9}

the nowcast h=0 for the variable y.

\subsection{Example}\label{example-9}

\begin{Shaded}
\begin{Highlighting}[]
 \KeywordTok{library}\NormalTok{(TextForecast)}
 \KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
 \KeywordTok{data}\NormalTok{(}\StringTok{"stock_data"}\NormalTok{)}
  \KeywordTok{data}\NormalTok{(}\StringTok{"news_data"}\NormalTok{)}
\NormalTok{ y=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{2}\NormalTok{])}
\NormalTok{ w=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{3}\NormalTok{])}
 \KeywordTok{data}\NormalTok{(}\StringTok{"news_data"}\NormalTok{)}
 \KeywordTok{data}\NormalTok{(}\StringTok{"optimal_factors_data"}\NormalTok{)}
\NormalTok{ pc=}\KeywordTok{as.matrix}\NormalTok{(optimal_factors)}
\NormalTok{ z=}\KeywordTok{cbind}\NormalTok{(w,pc)}
\NormalTok{ t=}\KeywordTok{length}\NormalTok{(y)}
\NormalTok{ ncsts=}\KeywordTok{text_nowcast}\NormalTok{(z,y[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{)],}\OtherTok{TRUE}\NormalTok{)}
 \KeywordTok{print}\NormalTok{(ncsts)}
\end{Highlighting}
\end{Shaded}

\section{Top Terms function}\label{top-terms-function}

This function computes the highest k predictive words by using the
highest absolute coefficient value.

\subsection{Arguments}\label{arguments-10}

\textbf{x:} the input matrix of terms to be selected.

\textbf{w:} optional argument. the input matrix of structured data to
not be selected.

\textbf{y:} the response variable

\textbf{alpha:} the glmnet alpha

\textbf{lambda:} the glmnet lambda

\textbf{k:} the k top terms

\textbf{wordcloud:} set TRUE to plot the wordcloud

\textbf{max.words:} the maximum number of words in the wordcloud

\textbf{scale:} the wordcloud size.

\textbf{rot.per:} wordcloud proportion 90 degree terms

\textbf{family:} glmnet family

\subsection{Value}\label{value-10}

the top k terms and the corresponding wordcloud.

\subsection{Example}\label{example-10}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(TextForecast)}
 \KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
 \KeywordTok{data}\NormalTok{(}\StringTok{"stock_data"}\NormalTok{)}
 \KeywordTok{data}\NormalTok{(}\StringTok{"news_data"}\NormalTok{)}
\NormalTok{ y=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{2}\NormalTok{])}
\NormalTok{ w=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{3}\NormalTok{])}
 \KeywordTok{data}\NormalTok{(}\StringTok{"news_data"}\NormalTok{)}
\NormalTok{ X=news_data[,}\DecValTok{2}\OperatorTok{:}\KeywordTok{ncol}\NormalTok{(news_data)]}
\NormalTok{ x=}\KeywordTok{as.matrix}\NormalTok{(X)}
\NormalTok{ grid_alphas=}\KeywordTok{seq}\NormalTok{(}\DataTypeTok{by=}\FloatTok{0.05}\NormalTok{,}\DataTypeTok{to=}\FloatTok{0.95}\NormalTok{,}\DataTypeTok{from=}\FloatTok{0.05}\NormalTok{)}
\NormalTok{ cont_folds=}\OtherTok{TRUE}
\NormalTok{ t=}\KeywordTok{length}\NormalTok{(y)}
\NormalTok{ optimal_alphas=}\KeywordTok{optimal_alphas}\NormalTok{(x[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],w[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],}
\NormalTok{ y[}\DecValTok{2}\OperatorTok{:}\NormalTok{t],grid_alphas,}\OtherTok{TRUE}\NormalTok{,}\StringTok{"gaussian"}\NormalTok{)}
\NormalTok{ top_trms<-}\StringTok{ }\KeywordTok{top_terms}\NormalTok{(x[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],w[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],y[}\DecValTok{2}\OperatorTok{:}\NormalTok{t],optimal_alphas[[}\DecValTok{1}\NormalTok{]],}
\NormalTok{optimal_alphas[[}\DecValTok{2}\NormalTok{]],}\DecValTok{10}\NormalTok{,}\OtherTok{TRUE}\NormalTok{,}\DecValTok{10}\NormalTok{,}\KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{,}\FloatTok{0.15}\NormalTok{),.}\DecValTok{15}\NormalTok{,}\StringTok{"gaussian"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\section{TV sentiment index function}\label{tv-sentiment-index-function}

\subsection{Arguments}\label{arguments-11}

\textbf{x:} A matrix of variables to be selected by shrinkrage methods.

\textbf{w:} Optional Argument. A matrix of variables to be selected by
shrinkrage methods.

\textbf{y:} the response variable.

\textbf{alpha:} the alpha required in glmnet.

\textbf{lambda:} the lambda required in glmnet.

\textbf{newx:} Matrix that selection will applied. Useful for time
series, when we need the observation at time t.

\textbf{family:} the glmnet family.

\textbf{k:} the highest positive and negative coefficients to be used.

\subsection{Value}\label{value-11}

The time-varying sentiment index. The index is based on the k word/term
counting and is computed using: tv\_index=(pos-neg)/(pos+neg).

\subsection{Example}\label{example-11}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(TextForecast)}
 \KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
 \KeywordTok{data}\NormalTok{(}\StringTok{"stock_data"}\NormalTok{)}
 \KeywordTok{data}\NormalTok{(}\StringTok{"news_data"}\NormalTok{)}
\NormalTok{ y=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{2}\NormalTok{])}
\NormalTok{ w=}\KeywordTok{as.matrix}\NormalTok{(stock_data[,}\DecValTok{3}\NormalTok{])}
 \KeywordTok{data}\NormalTok{(}\StringTok{"news_data"}\NormalTok{)}
\NormalTok{ X=news_data[,}\DecValTok{2}\OperatorTok{:}\KeywordTok{ncol}\NormalTok{(news_data)]}
\NormalTok{ x=}\KeywordTok{as.matrix}\NormalTok{(X)}
\NormalTok{ grid_alphas=}\KeywordTok{seq}\NormalTok{(}\DataTypeTok{by=}\FloatTok{0.05}\NormalTok{,}\DataTypeTok{to=}\FloatTok{0.95}\NormalTok{,}\DataTypeTok{from=}\FloatTok{0.05}\NormalTok{)}
\NormalTok{ cont_folds=}\OtherTok{TRUE}
\NormalTok{ t=}\KeywordTok{length}\NormalTok{(y)}
\NormalTok{ optimal_alphas=}\KeywordTok{optimal_alphas}\NormalTok{(x[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],w[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],}
\NormalTok{ y[}\DecValTok{2}\OperatorTok{:}\NormalTok{t],grid_alphas,}\OtherTok{TRUE}\NormalTok{,}\StringTok{"gaussian"}\NormalTok{)}
\NormalTok{  tv_index <-}\StringTok{ }\KeywordTok{tv_sentiment_index}\NormalTok{(x[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],w[}\DecValTok{1}\OperatorTok{:}\NormalTok{(t}\OperatorTok{-}\DecValTok{1}\NormalTok{),],}
\NormalTok{ y[}\DecValTok{2}\OperatorTok{:}\NormalTok{t],optimal_alphas[[}\DecValTok{1}\NormalTok{]],optimal_alphas[[}\DecValTok{2}\NormalTok{]],x,}\StringTok{"gaussian"}\NormalTok{,}\DecValTok{2}\NormalTok{)}
 \KeywordTok{head}\NormalTok{(tv_index)}
\end{Highlighting}
\end{Shaded}

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\hypertarget{ref-ahn2013eigenvalue}{}
Ahn, Seung C, and Alex R Horenstein. 2013. ``Eigenvalue Ratio Test for
the Number of Factors.'' \emph{Econometrica} 81 (3). Wiley Online
Library: 1203--27.

\hypertarget{ref-bai2008forecasting}{}
Bai, Jushan, and Serena Ng. 2008. ``Forecasting Economic Time Series
Using Targeted Predictors.'' \emph{Journal of Econometrics} 146 (2).
Elsevier: 304--17.

\hypertarget{ref-godeiro2018ensaios}{}
Godeiro, Lucas. 2018. ``Ensaios Sobre Modelos de Previsao Economica.''
Universidade Federal da Paraíba.

\hypertarget{ref-limagodeiromohsin2018}{}
Lima, Luiz Renato, Lucas Lúcio Godeiro, and Mohammed Mohsin. 2018.
``Time-Varying Dictionary and the Predictive Power of Fed Minutes.'' In
\emph{2018 Ciret Biennial International Conference}.


\end{document}
